{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************************************************************************\n",
    "#\n",
    "# Copyright 2026\n",
    "#   Murayyiam Parvez (Purdue University),\n",
    "#   Annus Zulfiqar (University of Michigan),\n",
    "#   Roman Beltiukov (University of California, Santa Barbara),\n",
    "#   Shir Landau Feibish (The Open University of Israel),\n",
    "#   Walter Willinger (NIKSUN Inc.),\n",
    "#   Arpit Gupta (University of California, Santa Barbara),\n",
    "#   Muhammad Shahbaz (University of Michigan)\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#\n",
    "# *****************************************************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To read from our text results and push to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read a results file and return a list of model performances\n",
    "def get_results(this_file):\n",
    "    print(f\"Reading file: {this_file}\")\n",
    "    these_models = []\n",
    "\n",
    "    # read all results\n",
    "    with open(this_file, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # convert each line result to a model performance\n",
    "    for line in lines:\n",
    "        words = line.split()\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            print(f\"{i}: {word}\")\n",
    "\n",
    "            max_depth = int(words[0])\n",
    "            features_per_partition = int(words[1])\n",
    "            c1 = float(words[2])\n",
    "            c2 = float(words[3])\n",
    "            c3 = float(words[4])\n",
    "            c4 = float(words[5])\n",
    "            c5 = float(words[6])\n",
    "            c6 = float(words[7])\n",
    "            num_partitions = int(words[8])\n",
    "            f1_score = float(words[9])\n",
    "            num_flows = int(words[10])\n",
    "            is_feasible = bool(words[11])\n",
    "            total_features = int(words[12])\n",
    "            feature_entries = int(words[13])\n",
    "            table_entries = int(words[14])\n",
    "            \n",
    "            model.ModelConfig(\n",
    "                max_depth=max_depth,\n",
    "                features_per_partition=features_per_partition,\n",
    "                c1=c1, c2=c2, c3=c3, c4=c4, c5=c5, c6=c6,\n",
    "                num_partitions=num_partitions,\n",
    "                f1_score=f1_score,\n",
    "                num_flows=num_flows,\n",
    "                feasible=is_feasible,\n",
    "                total_features=total_features,\n",
    "                feature_entries=feature_entries,\n",
    "                table_entries=table_entries\n",
    "            )\n",
    "\n",
    "                \n",
    "        break\n",
    "\n",
    "    return these_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: /home/annuszulfiqar/research/NetEye/dt-framework/results/hypermapper-bayesian_optimization-CIC-IoMT-2024-PCAPS1-f10-2024-12-07-17:38:53/results-d20.txt\n",
      "0: Max\n",
      "1: Depth\n",
      "2: =\n",
      "3: 20,\n",
      "4: Feature\n",
      "5: Limit\n",
      "6: =\n",
      "7: 3,\n",
      "8: Total\n",
      "9: Features\n",
      "10: =\n",
      "11: 38,\n",
      "12: Number\n",
      "13: of\n",
      "14: Partitions\n",
      "15: =\n",
      "16: 7,\n",
      "17: F1\n",
      "18: Score\n",
      "19: =\n",
      "20: 0.3626194850655502,\n",
      "21: Feature\n",
      "22: Table\n",
      "23: Entries\n",
      "24: =\n",
      "25: 3067,\n",
      "26: Tree\n",
      "27: Table\n",
      "28: Entries\n",
      "29: =\n",
      "30: 1041,\n",
      "31: Number\n",
      "32: of\n",
      "33: flows\n",
      "34: =\n",
      "35: 262144.0,\n",
      "36: Partition\n",
      "37: Sizes\n",
      "38: =\n",
      "39: [2,\n",
      "40: 5,\n",
      "41: 1,\n",
      "42: 4,\n",
      "43: 3,\n",
      "44: 4,\n",
      "45: 1],\n",
      "46: Resubmission\n",
      "47: Traffic\n",
      "48: =\n",
      "49: 0.088,\n",
      "50: Model\n",
      "51: Features\n",
      "52: =\n",
      "53: {'Bwd\n",
      "54: Packet\n",
      "55: Length\n",
      "56: Mean',\n",
      "57: 'Bwd\n",
      "58: IAT\n",
      "59: Min',\n",
      "60: 'Total\n",
      "61: Length\n",
      "62: of\n",
      "63: Fwd\n",
      "64: Packet',\n",
      "65: 'Dst\n",
      "66: Port',\n",
      "67: 'Fwd\n",
      "68: IAT\n",
      "69: Max',\n",
      "70: 'Flow\n",
      "71: Bytes/s',\n",
      "72: 'ACK\n",
      "73: Flag\n",
      "74: Count',\n",
      "75: 'Bwd\n",
      "76: Packet\n",
      "77: Length\n",
      "78: Min',\n",
      "79: 'Fwd\n",
      "80: PSH\n",
      "81: Flags',\n",
      "82: 'Bwd\n",
      "83: IAT\n",
      "84: Mean',\n",
      "85: 'Total\n",
      "86: Fwd\n",
      "87: Packet',\n",
      "88: 'Fwd\n",
      "89: Packet\n",
      "90: Length\n",
      "91: Max',\n",
      "92: 'Flow\n",
      "93: Duration',\n",
      "94: 'Fwd\n",
      "95: IAT\n",
      "96: Total',\n",
      "97: 'Packet\n",
      "98: Length\n",
      "99: Mean',\n",
      "100: 'Bwd\n",
      "101: Packets/s',\n",
      "102: 'Fwd\n",
      "103: Packet\n",
      "104: Length\n",
      "105: Min',\n",
      "106: 'Bwd\n",
      "107: Header\n",
      "108: Length',\n",
      "109: 'Flow\n",
      "110: IAT\n",
      "111: Mean',\n",
      "112: 'Bwd\n",
      "113: Segment\n",
      "114: Size\n",
      "115: Avg',\n",
      "116: 'Average\n",
      "117: Packet\n",
      "118: Size',\n",
      "119: 'Fwd\n",
      "120: Header\n",
      "121: Length',\n",
      "122: 'Fwd\n",
      "123: IAT\n",
      "124: Min',\n",
      "125: 'Fwd\n",
      "126: Act\n",
      "127: Data\n",
      "128: Pkts',\n",
      "129: 'FIN\n",
      "130: Flag\n",
      "131: Count',\n",
      "132: 'Flow\n",
      "133: IAT\n",
      "134: Max',\n",
      "135: 'Bwd\n",
      "136: IAT\n",
      "137: Total',\n",
      "138: 'Flow\n",
      "139: IAT\n",
      "140: Min',\n",
      "141: 'Fwd\n",
      "142: IAT\n",
      "143: Mean',\n",
      "144: 'Total\n",
      "145: Length\n",
      "146: of\n",
      "147: Bwd\n",
      "148: Packet',\n",
      "149: 'Fwd\n",
      "150: Seg\n",
      "151: Size\n",
      "152: Min',\n",
      "153: 'Fwd\n",
      "154: Packet\n",
      "155: Length\n",
      "156: Mean',\n",
      "157: 'Packet\n",
      "158: Length\n",
      "159: Max',\n",
      "160: 'Fwd\n",
      "161: Packets/s',\n",
      "162: 'Bwd\n",
      "163: IAT\n",
      "164: Max',\n",
      "165: 'Fwd\n",
      "166: Segment\n",
      "167: Size\n",
      "168: Avg',\n",
      "169: 'Flow\n",
      "170: Packets/s',\n",
      "171: 'SYN\n",
      "172: Flag\n",
      "173: Count'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_dir = \"/home/annuszulfiqar/research/NetEye/dt-framework/results/hypermapper-bayesian_optimization-CIC-IoMT-2024-PCAPS1-f10-2024-12-07-17:38:53\"\n",
    "\n",
    "for this_file in os.listdir(results_dir):\n",
    "    test_file = os.path.join(results_dir, this_file)\n",
    "    # see if extension is .txt\n",
    "    if test_file.endswith(\".txt\"):\n",
    "        model_perfs = get_results(test_file)\n",
    "\n",
    "        \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
